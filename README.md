<!-- README.md is generated from README.Rmd. Please edit that file -->
bama
====

bama
====

`bama` is a Bayesian inference method that uses continuous shrinkage
priors for high-dimensional Bayesian mediation analysis, developed by
Song et al (2018). `bama` provides estimates for the regression
coefficients as well as the posterior inclusion probability for ranking
mediators.

Installation
------------

You can install `bama` via CRAN

    install.packages("bama")

Or devtools

    devtools::install_github("umich-cphds/bama", build_opts = c())

If you wish to install the package via devtools, you will need a C++
compiler installed. This can be accomplished by installing Rtools on
Windows and Xcode on MacOS.

Example
-------

Taken from the `bama` help file

    library(bama)

    Y <- bama.data$y
    A <- bama.data$a

    # grab the mediators from the example data.frame
    M <- as.matrix(bama.data[, paste0("m", 1:100)], nrow(bama.data))

    # We just include the intercept term in this example.
    C <- matrix(1, nrow(M), 1)
    beta.m  <- rep(0, 100)
    alpha.a <- rep(0, 100)

    set.seed(1245)
    bama.out <- bama(Y, A, M, C, C, beta.m, alpha.a, burnin = 3000, ndraws = 100)

    # Rank mediators and see summary information
    summary(bama.out, rank = T)
    #>           estimate     ci.lower    ci.upper  pip
    #> m65  -0.2669498551 -0.335969389 -0.18964906 1.00
    #> m12   0.2065314024  0.124436993  0.28020939 0.99
    #> m89  -0.1522816578 -0.218542178 -0.06832073 0.89
    #> m93   0.0433847283 -0.003451208  0.10405256 0.16
    #> m22  -0.0329333459 -0.099433981  0.02209072 0.13
    #> m97  -0.0337249047 -0.084701429  0.01362444 0.11
    #> m67   0.0129102782 -0.030515881  0.06475983 0.06
    #> m69  -0.0046510372 -0.039527107  0.03968501 0.05
    #> m37   0.0014736373 -0.045460946  0.05083276 0.04
    #> m42  -0.0200836145 -0.065202153  0.02006685 0.04
    #> m19  -0.0022000371 -0.046321330  0.03951422 0.03
    #> m21   0.0073261212 -0.031859425  0.04620292 0.03
    #> m29  -0.0107482568 -0.054492539  0.02794998 0.03
    #> m48  -0.0042349713 -0.037533606  0.03709028 0.03
    #> m86   0.0199181481 -0.017058425  0.07149214 0.03
    #> m88  -0.0086262816 -0.054123032  0.02621741 0.03
    #> m20  -0.0079515212 -0.048993399  0.03701881 0.02
    #> m39  -0.0077103887 -0.041974723  0.02888687 0.02
    #> m41  -0.2744837283 -0.325538269 -0.20669783 0.02
    #> m57   0.0154657140 -0.032079776  0.05768428 0.02
    #> m58   0.0025620219 -0.037725402  0.03928200 0.02
    #> m62   0.0063873301 -0.039393129  0.05662959 0.02
    #> m68   0.1503645957  0.054122336  0.22027305 0.02
    #> m76   0.0072729278 -0.028047079  0.03942734 0.02
    #> m84   0.0046434102 -0.038340184  0.04650754 0.02
    #> m26  -0.0010443802 -0.043837818  0.04330054 0.01
    #> m59  -0.0356179686 -0.086583527  0.01546436 0.01
    #> m66  -0.0167660030 -0.072567020  0.02968608 0.01
    #> m72   0.0098400345 -0.029765134  0.05971788 0.01
    #> m92  -0.0163165734 -0.058101573  0.02082817 0.01
    #> m99   0.1215997564 -0.011893078  0.27305331 0.01
    #> m1    0.0139226959 -0.029325518  0.06672816 0.00
    #> m2    0.0126664691 -0.025197153  0.05427589 0.00
    #> m3    0.0086559010 -0.032485778  0.05070052 0.00
    #> m4    0.0142841213 -0.027939579  0.04821840 0.00
    #> m5    0.0385472433 -0.022576947  0.21340102 0.00
    #> m6    0.0109733295 -0.021767222  0.05030581 0.00
    #> m7    0.0073564407 -0.038972863  0.05158557 0.00
    #> m8   -0.0122790834 -0.045044644  0.02201488 0.00
    #> m9    0.0297304932 -0.013669618  0.07701433 0.00
    #> m10  -0.0006779005 -0.047956768  0.04793432 0.00
    #> m11   0.0227833760 -0.016410879  0.07292715 0.00
    #> m13   0.0067380079 -0.040691713  0.04508875 0.00
    #> m14  -0.0010038326 -0.043574458  0.03944084 0.00
    #> m15   0.0021201044 -0.034287015  0.03671952 0.00
    #> m16  -0.0101770569 -0.053280911  0.02558790 0.00
    #> m17  -0.0093120241 -0.063286900  0.03397353 0.00
    #> m18   0.0020712255 -0.042456138  0.04461800 0.00
    #> m23   0.0026706394 -0.046772843  0.03434620 0.00
    #> m24   0.0034861207 -0.035884596  0.05136032 0.00
    #> m25  -0.0079190512 -0.052317526  0.03078571 0.00
    #> m27   0.0168799936 -0.022811598  0.06090186 0.00
    #> m28  -0.0228915165 -0.072943977  0.01185096 0.00
    #> m30   0.0002347126 -0.046957010  0.03901866 0.00
    #> m31   0.0054127016 -0.038142303  0.05024922 0.00
    #> m32  -0.0083748952 -0.058058115  0.04136777 0.00
    #> m33  -0.0255823752 -0.083387149  0.00813171 0.00
    #> m34  -0.0010177469 -0.046212310  0.03337269 0.00
    #> m35  -0.0103268955 -0.051814557  0.02240294 0.00
    #> m36   0.0168359413 -0.021520270  0.07777135 0.00
    #> m38   0.0197544534 -0.011980490  0.06727677 0.00
    #> m40   0.0003104215 -0.044228716  0.04498964 0.00
    #> m43  -0.0024397709 -0.042947139  0.04204366 0.00
    #> m44   0.0453509704  0.002491828  0.12086918 0.00
    #> m45   0.0107527179 -0.038684067  0.05930722 0.00
    #> m46   0.0082418482 -0.032839167  0.05610630 0.00
    #> m47  -0.0047079254 -0.044257884  0.03289759 0.00
    #> m49  -0.0070584698 -0.040679761  0.03435359 0.00
    #> m50   0.0205002741 -0.025481669  0.06375452 0.00
    #> m51  -0.0216608474 -0.069342720  0.03428494 0.00
    #> m52   0.0007050909 -0.047414531  0.04344711 0.00
    #> m53   0.0049138031 -0.030792277  0.04517474 0.00
    #> m54   0.0089235128 -0.033691663  0.04930259 0.00
    #> m55  -0.0061848261 -0.042102384  0.03195833 0.00
    #> m56  -0.0076390893 -0.047233477  0.02955647 0.00
    #> m60  -0.0067954345 -0.055202537  0.03148131 0.00
    #> m61   0.0171367613 -0.032756697  0.05806250 0.00
    #> m63  -0.0030772224 -0.039263489  0.03777886 0.00
    #> m64   0.0035493546 -0.043205222  0.04301582 0.00
    #> m70   0.0044607087 -0.040248416  0.04550695 0.00
    #> m71  -0.0025633480 -0.041426307  0.03552411 0.00
    #> m73  -0.0001958797 -0.042822252  0.03602552 0.00
    #> m74   0.0055022808 -0.026247283  0.04610611 0.00
    #> m75   0.0380959141 -0.013723460  0.19250327 0.00
    #> m77   0.0092398537 -0.025386740  0.06008805 0.00
    #> m78   0.0010362510 -0.037130685  0.04539834 0.00
    #> m79   0.0233703264 -0.007760143  0.06627593 0.00
    #> m80   0.0234506961 -0.012763910  0.06885443 0.00
    #> m81  -0.2586523140 -0.321360463 -0.19792202 0.00
    #> m82  -0.0206905227 -0.061827303  0.01946687 0.00
    #> m83  -0.0037308997 -0.044306907  0.03183278 0.00
    #> m85   0.0010555279 -0.040636021  0.03657142 0.00
    #> m87   0.0016603850 -0.038061617  0.04702774 0.00
    #> m90  -0.0228173791 -0.055344291  0.01144337 0.00
    #> m91   0.0055673463 -0.038307932  0.04755510 0.00
    #> m94   0.0040074273 -0.036598016  0.04522954 0.00
    #> m95   0.0132530452 -0.028660534  0.06251141 0.00
    #> m96   0.0022798217 -0.039487853  0.04575167 0.00
    #> m98  -0.0084901539 -0.051016741  0.03798838 0.00
    #> m100  0.0075559799 -0.026937358  0.05526565 0.00

Reference
=========

Yanyi Song, Xiang Zhou et al. Bayesian Shrinkage Estimation of High
Dimensional Causal Mediation Effects in Omics Studies. [bioRxiv
467399](https://doi.org/10.1101/467399)
